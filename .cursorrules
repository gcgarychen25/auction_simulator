# Auction Simulator Development Rules

## Code Quality & Documentation
- **Always highlight placeholders** and summarize places waiting for user input
- **Comprehensive analytics**: Every data analysis should include individual plot explanations, metric interpretations, and strategic implications
- **Structured reports**: Auto-generate markdown reports with detailed analysis of each visualization
- **Professional formatting**: Use emojis and clear section headers for readability

## Analytics Standards
- **6-panel dashboards**: Price distribution, winner analysis, surplus breakdown, episode length, consistency trends, efficiency metrics
- **Economic interpretation**: Always explain welfare efficiency, allocative efficiency, and revenue efficiency
- **Phase 2 readiness**: Include RL development implications, baseline targets, and training considerations
- **Market dynamics**: Analyze competitive patterns, persona performance, and mechanism effectiveness

## Persona Development
- **Dual randomness approach**: Policy-level decision randomness + configurable persona parameter variation
- **Maintain persona identity**: Strategic behavior should align with buyer archetypes (Conservative, Aggressive, Analytical, Budget-Conscious, FOMO)
- **Configurable variation**: Support both deterministic research and realistic market simulation modes
- **Episode-level consistency**: Persona variations fixed per episode, not per decision

## System Architecture
- **Modular design**: Separate analytics, policies, and environment components
- **Batch simulation support**: Auto-trigger analysis for datasets with 10+ episodes  
- **Parallel tool execution**: Run multiple read-only operations simultaneously for efficiency
- **Error handling**: Graceful degradation with clear error messages and debugging paths

## Research Methodology
- **Baseline establishment**: Always run sufficient episodes (50-100) for statistical significance
- **Comparative analysis**: Include efficiency benchmarking against theoretical optimums
- **Strategic insights**: Identify opportunities for improvement in subsequent phases
- **Reproducible results**: Maintain configuration traceability and seed management

## User Experience
- **Immediate feedback**: Provide progress indicators and interim results during long operations
- **Clear summaries**: Executive summaries with key findings at multiple detail levels
- **Visual dashboards**: Professional visualizations with proper axes, legends, and annotations
- **Actionable insights**: Always conclude with specific next steps or recommendations

## Development Patterns
- **Phase-driven development**: Clear separation between Monte Carlo baseline (Phase 1) and RL development (Phase 2)
- **Configuration-driven behavior**: Use YAML configs for easy experimentation without code changes
- **Comprehensive logging**: Structured round-based logs with state information and action summaries
- **Integration testing**: Validate end-to-end workflows with realistic data volumes 